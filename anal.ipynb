{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38664bittorchgeoconda6f756dd914a64c5bbfcc12322cd6a319",
   "display_name": "Python 3.8.6 64-bit ('torch_geo': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import plot_tree\n",
    "\n",
    "# 分类器们\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "source": [
    "数据前处理\n",
    "\n",
    "X,Y是训练集\n",
    "x,y是测试集"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#处理训练集\n",
    "raw=pd.read_csv(\"./data/train.csv\")\n",
    "rawX=raw.loc[:,\"XXXinorg1\":\"purity\"]\n",
    "Y=Y=np.array((raw.loc[:,\"outcome\"]),dtype=np.float64)\n",
    "#处理测试集\n",
    "raw=pd.read_csv(\"./data/test.csv\")\n",
    "human_pred=np.array(raw.loc[:,\"XXX-Intuition\"],dtype=np.float64)\n",
    "ml_pred=np.array(raw.loc[:,\"predicted outcome\"],dtype=np.float64)\n",
    "y=np.array(raw.loc[:,\"outcome (actual)\"],dtype=np.float64)\n",
    "rawx=raw.loc[:,\"XXXinorg1\":\"purity\"]\n",
    "np.save(\"./processedData/Y.npy\",Y)\n",
    "np.save(\"./processedData/y.npy\",y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawXx=pd.concat([rawX,rawx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureName=list(rawXx)"
   ]
  },
  {
   "source": [
    "对3个feature进行特判\n",
    "\n",
    "分为实数型，字符串型，bool型\n",
    "\n",
    "第二类使用独热编码处理\n",
    "\n",
    "其中有三个特征比较特殊：\n",
    "slowCool{'?', 'no', 'yes'}\n",
    "\n",
    "XXXoxlike1{'-1', -1, 'sodium oxalate'}\n",
    "\n",
    "leak{'?', 'no', 'yes'}\n",
    "\n",
    "\"no\" 赋为0，yes赋1，? 用为yes的概率代替\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_featureName=[]\n",
    "Xx=np.array([],dtype=np.float64).reshape(len(rawXx),-1)\n",
    "boolFeature=[]\n",
    "oneHotFeature=[]\n",
    "errorFeature=[]\n",
    "encoders={}\n",
    "for i in featureName:\n",
    "    try:\n",
    "        feature=np.array(rawXx.loc[:,i],dtype=np.float64).reshape(-1,1)\n",
    "    except:\n",
    "        featureval=set(rawXx.loc[:,i])\n",
    "        if(len(featureval)==1):# 只有一种值的特征，没有帮助\n",
    "            continue\n",
    "        elif(featureval==set([\"yes\",\"no\"])):# bool 型\n",
    "            feature=np.array(rawXx.loc[:,i]=='yes',dtype=np.float64).reshape(-1,1)\n",
    "            boolFeature.append(i)\n",
    "        elif(featureval==set([\"yes\",\"no\",\"?\"])):# 需要补全的bool 型\n",
    "            valCnt=rawXx.loc[:,i].value_counts()\n",
    "            ratio=(valCnt[\"yes\"])/(valCnt['no'])\n",
    "            feature=np.array((rawXx.loc[:,i]=='yes')\n",
    "                +((rawXx.loc[:,i]=='?')*(ratio/(1+ratio))),dtype=np.float64).reshape(-1,1)\n",
    "            boolFeature.append(i)\n",
    "        else:\n",
    "            print(i)# 独热型\n",
    "            ohe=OneHotEncoder()\n",
    "            feature=ohe.fit_transform(np.array(rawXx.loc[:,i],dtype=str).reshape(-1,1)).toarray()\n",
    "            if(feature.shape[1]>200):\n",
    "                errorFeature.append(i)\n",
    "                continue\n",
    "            else:\n",
    "                oneHotFeature.append(i)\n",
    "                encoders[i]=ohe\n",
    "    X_featureName+=[i]*(feature.shape[1])\n",
    "    Xx=np.concatenate((Xx,feature),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=Xx[:len(rawX),:]\n",
    "x=Xx[len(rawX):,:]"
   ]
  },
  {
   "source": [
    "将处理好的数据放在文件中"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./processedData/Y.npy\",Y)\n",
    "np.save(\"./processedData/y.npy\",y)\n",
    "np.save(\"./processedData/Xx.npy\",Xx)\n",
    "np.save(\"./processedData/X_featureName.npy\",X_featureName)\n",
    "np.save(\"./processedData/errorFeature.npy\",errorFeature)\n",
    "np.save(\"./processedData/oneHotFeature.npy\",oneHotFeature)\n",
    "np.save(\"./processedData/boolFeature.npy\",boolFeature)\n",
    "np.save(\"./processedData/encoders.npy\",encoders)"
   ]
  },
  {
   "source": [
    "SVM\n",
    "\n",
    "crossValidation\n",
    "对数据集进行shuffle能显著提高性能,但这是虚假的。作者需要求出未知化合物组合的效果\n",
    "shuffle=True是随机取样。但是作者的策略是把同一反应物组合的化合物放到一起(恰好在csv中反应物组合近似的放在一起)。则shuffle=False即可。\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numout2boolout(label):# 结果有1，2，3，4。但是3，4对应人的预测1，1，2\n",
    "    return label>2.5\n",
    "def crossValidation(X,y,n_splits,Model,params,shuffle=False):\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    kf=KFold(n_splits=n_splits,shuffle=shuffle)\n",
    "    print(params)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X_std[train_index], X_std[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        model=Model(**params)\n",
    "        model.fit(X_train,Y_train)\n",
    "        tr_pred=model.predict(X_train)\n",
    "        tr_pred=numout2boolout(tr_pred)\n",
    "        Y_train=numout2boolout(Y_train)\n",
    "        print(\"recall={:.3f}\".format(recall_score(Y_train,tr_pred,average='weighted')))\n",
    "        print(\"precision={:.3f}\".format(precision_score(Y_train,tr_pred,average=\"weighted\")))\n",
    "        print(\"accuracy={:.3f}\".format(accuracy_score(Y_train,tr_pred)))\n",
    "        print(\"confusion matrix is\")\n",
    "        print(confusion_matrix(Y_train,tr_pred))\n",
    "        \n",
    "        pred=model.predict(X_test)\n",
    "        Y_test=numout2boolout(Y_test)\n",
    "        pred=numout2boolout(pred)\n",
    "        print(\"recall={:.3f}\".format(recall_score(Y_test,pred,average='weighted')))\n",
    "        print(\"precision={:.3f}\".format(precision_score(Y_test,pred,average=\"weighted\")))\n",
    "        print(\"accuracy={:.3f}\".format(accuracy_score(Y_test,pred)))\n",
    "        print(\"confusion matrix is\")\n",
    "        print(confusion_matrix(Y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    (SVC,{\"gamma\":2, \"C\":1}),\n",
    "    #(GaussianProcessClassifier,{\"kernel\":1.0 * RBF(1.0)}),# slow\n",
    "    (DecisionTreeClassifier,{\"max_depth\":5}),\n",
    "    (RandomForestClassifier,{\"max_depth\":5, \"n_estimators\":10, \"max_features\":1}),\n",
    "    (MLPClassifier,{\"alpha\":1, \"max_iter\":1000}),\n",
    "    (AdaBoostClassifier,{}),\n",
    "    (GaussianNB,{}),\n",
    "    (QuadraticDiscriminantAnalysis,{})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in classifiers:\n",
    "    crossValidation(X,Y,3,i[0],i[1])"
   ]
  },
  {
   "source": [
    "文献中使用的svm https://github.com/rlphilli/sklearn-PUK-kernel/blob/master/PUK_kernel.py\n",
    "\n",
    "以下函数是文献中使用的svm核，效果不如RBF核"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, cdist\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "def PUK_kernel(X1,X2, sigma=1.0, omega=1.0):\n",
    "    # Compute the kernel matrix between two arrays using the Pearson VII function-based universal kernel.\n",
    "    \n",
    "    # Compute squared euclidean distance between each row element pair of the two matrices\n",
    "    if X1 is X2 :\n",
    "        kernel = squareform(pdist(X1, 'sqeuclidean'))\n",
    "    else:\n",
    "        kernel = cdist(X1, X2, 'sqeuclidean')\n",
    "\n",
    "    kernel = (1 + (kernel * 4 * np.sqrt(2**(1.0/omega)-1)) / sigma**2) ** omega\n",
    "    kernel = 1/kernel\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "source": [
    "很糟，train,testset差别太大"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossValidation(X,Y,3,SVC,{\"kernel\":PUK_kernel,\"class_weight\":\"balanced\",\"C\":1})"
   ]
  },
  {
   "source": [
    "将相同反应物的反应聚在一起再shuffle，达到了原文献的效果"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "reactantMask选择了表示反应物组合的特征。"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb=[]\n",
    "reactantCombination=[]\n",
    "reactantMask=[\"XXXinorg1\",\"XXXinorg2\",\"XXXinorg3\",\"XXXorg1\",\"XXXorg2\"]\n",
    "for i in range(0,len(rawX)):\n",
    "    try:\n",
    "        id=comb.index(set(rawX.loc[i,reactantMask]))\n",
    "        reactantCombination[id].append(i)\n",
    "    except:\n",
    "        comb.append(set(rawX.loc[i,reactantMask]))\n",
    "        reactantCombination.append([i])\n",
    "\n",
    "def CV_author(X,Y,n_splits,Model,params,shuffle=True):\n",
    "    scaler = StandardScaler()\n",
    "    X_std = scaler.fit_transform(X)\n",
    "    kf=KFold(n_splits=n_splits,shuffle=shuffle)\n",
    "    print(params)\n",
    "    for train_index_rc, test_index_rc in kf.split(reactantCombination):\n",
    "        train_index=[i for rc  in train_index_rc  for i in reactantCombination[rc] ]\n",
    "        test_index=[i for rc  in test_index_rc  for i in reactantCombination[rc]]\n",
    "        X_train, X_test = X_std[train_index], X_std[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "        model=Model(**params)\n",
    "        model.fit(X_train,Y_train)\n",
    "        \n",
    "        pred=model.predict(X_test)\n",
    "        Y_test=numout2boolout(Y_test)\n",
    "        pred=numout2boolout(pred)\n",
    "        print(\"recall={:.3f}\".format(recall_score(Y_test,pred,average='weighted')))\n",
    "        print(\"precision={:.3f}\".format(precision_score(Y_test,pred,average=\"weighted\")))\n",
    "        print(\"accuracy={:.3f}\".format(accuracy_score(Y_test,pred)))\n",
    "        print(\"confusion matrix is\")\n",
    "        print(confusion_matrix(Y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_author(X,Y,3,SVC,{\"kernel\":PUK_kernel,\"class_weight\":\"balanced\",\"C\":1})"
   ]
  },
  {
   "source": [
    "对测试集的测试"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVC(kernel=PUK_kernel,class_weight=\"balanced\",C=1)\n",
    "model.fit(X,Y)\n",
    "pred=model.predict(x)\n",
    "print(precision_score(numout2boolout(y),numout2boolout(pred)))"
   ]
  },
  {
   "source": [
    "将模型解释为决策树, 使用sklearn.tree.plot_tree进行可视化\n",
    "\n",
    "注意决策树只使用一些特征进行重解释，用tree_X_mask表示"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinterpret(X_model,model,X_tree):\n",
    "    pred=model.predict(X_model)\n",
    "    ret=DecisionTreeClassifier()\n",
    "    ret.fit(X_tree,pred)\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_tree_X_mask(s):\n",
    "    for i in [\"orgvanderwaals\",\"orgASA+\",\"orghbdamsdon\",\"PaulingElectronegMean\", \"hardnessMeanWeighted\", \"AtomicRadiusMeanWeighted\"]:\n",
    "        if i in s:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_X_mask=[i for i in range(len(X_featureName)) if in_tree_X_mask(X_featureName[i])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree=reinterpret(X,model,X[:,tree_X_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tree(tree,max_depth=5,feature_names=[X_featureName[i] for i in tree_X_mask])"
   ]
  },
  {
   "source": [
    "特征选择"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "sklearn应该没有实现CFS方法，但是可以用其他方法，此处没有实现"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "sfm = SelectFromModel(LassoCV(), ).fit(X, y)\n",
    "toc = time()\n",
    "print(\"Features selected by SelectFromModel: \"\n",
    "      f\"{feature_names[sfm.get_support()]}\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}